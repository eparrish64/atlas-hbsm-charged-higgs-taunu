#! /usr/bin/env python

"""
* this script is meant for fake factors calculation in some dedicated control regions
* and then combining them in the signal region/other CR regions depending on the composition
* of the jets faking taus (quark or gluon type jets).
"""

## stdlib
import os, sys, time, array, pickle, copy, random
import multiprocessing


## PyPI
import numpy as np
from tabulate import tabulate
import yaml

# - - - - - - - -  parse ana args (needed before ROOT)
from hpana.cmd import get_ffs_parser 
ffs_parser = get_ffs_parser()
FFs_ARGS = ffs_parser.parse_args()

## local
from hpana.rqcd import get_cr_ffs, fit_alpha, prep_ff_hists, fake_sources, plot_cr_ffs, plot_alpha 
from hpana.variables import rQCD_VARS, FFS_TEMPLATE_VARS, tau_0_jet_width, tau_0_jet_bdt_score_trans
from hpana.categories import (
    FAKE_TAU_SOURCE,
    FF_CR_MULTIJET,
    FF_CR_WJETS,
    Category_BVETO,
    Category_SR_TAUJET,
    Category_SR_TAULEP,
    Category_TAUEL_BVETO,
    Category_TAUMU_BVETO,
    Category_SS_TAUEL,
    Category_SS_TAUMU)
    
from hpana.dataset_hists import dataset_hists
from hpana.config import Configuration
from hpana.analysis import Analysis
from hpana.samples.fakes import QCD
from hpana import log


# - - - - time it
start_time = time.time()


# - - - - - - - -  set log level
log.setLevel(FFs_ARGS.log)

# - - - - - - - - Speed things up a bit
import ROOT
ROOT.SetSignalPolicy(ROOT.kSignalFast)
ROOT.gROOT.SetBatch(True)
ROOT.gROOT.SetStyle("ATLAS")
log.debug("ROOT is in batch mode")
ROOT.gErrorIgnoreLevel = ROOT.kWarning #<! turn off useless ROOT Info messages (tons of them for Chi2 fit)

##------------------------------------------------------------------------------------
## - - build both taujet and taulep analyses (FF CR s are for different channels)
##------------------------------------------------------------------------------------
taujet_config = Configuration("taujet",
                              mc_campaign="mc16", data_streams=FFs_ARGS.data_streams, db_version=FFs_ARGS.db_version)
taujet_analysis = Analysis(taujet_config, compile_cxx=True)
taujet_analysis.data.blind = False #<! no blinding for FFs calculation

taulep_config = Configuration("taulep",
                              mc_campaign="mc16", data_streams=FFs_ARGS.data_streams, db_version=FFs_ARGS.db_version)
taulep_analysis = Analysis(taulep_config, compile_cxx=True)
taulep_analysis.data.blind = False


##------------------------------------------------------------------------------------
## - - consts 
##------------------------------------------------------------------------------------
COLORS = [ROOT.kRed, ROOT.kBlue, ROOT.kBlack, ROOT.kMagenta, ROOT.kOrange, ROOT.kGreen]
LOOSE_TAU = ROOT.TCut("tau_0_jet_bdt_loose==0")
N_CHARGED_TRACKS = [1, 3] 
TAU_PT_BINS = {
    "1":[30, 35, 40, 45, 50, 60, 80, 100, 200, 3500],
    "3":[30, 35, 40, 60, 80, 100, 3500],
}

## - - - - CR and target selection regions
TAULEP_TARGET_REGIONS = taulep_config.categories + taulep_config.ff_cr_regions
TAUJET_TARGET_REGIONS = taujet_config.categories + taujet_config.ff_cr_regions
TARGET_REGIONS = TAUJET_TARGET_REGIONS + TAULEP_TARGET_REGIONS
FFS_CONTROL_REGIONS = taulep_config.ff_cr_regions #+taujet_config.ff_cr_regions + 


## - - - - hist template for rQCD calculation
FIT_HIST_TEMPLATES = {
    #<! PLS NOTE the tformula order is Z:Y:X and for the binning it's X, Y, Z !
    "tau_0_jet_width":
    ROOT.TH3F("tau_0_p4->Pt():tau_0_n_charged_tracks:tau_0_jet_width_trks_dr04", "tau_0_jet_width", 20, 0, .4, 4, 0, 4, 800, 0, 4000),
    "tau_0_jet_bdt_score_trans":
    ROOT.TH3F("tau_0_p4->Pt():tau_0_n_charged_tracks:tau_0_jet_bdt_score_trans", "tau_0_jet_bdt_score_trans", 50, 0, .5, 4, 0, 4, 800, 0, 4000),
}

## - - - - samples with true tau, lep faking tau and data
TAUJET_SAMPLES = [taujet_analysis.data,]
TAULEP_SAMPLES = [taulep_analysis.data,]

if FFs_ARGS.samples:
    TAUJET_SAMPLES = filter(lambda s: s.name in FFs_ARGS.samples, TAUJET_SAMPLES)
    TAULEP_SAMPLES = filter(lambda s: s.name in FFs_ARGS.samples, TAULEP_SAMPLES)

if __name__=="__main__":
    ##------------------------------------------------------------------------------------
    ## - - Fake tau source 
    ##------------------------------------------------------------------------------------
    if FFs_ARGS.fake_sources:
        all_events = {}
        regions = ["SR_TAUJET", "SR_TAULEP", "FF_CR_MULTIJET", "FF_CR_WJETS"]
        fnames = ["electron", "lquark", "cquark", "bquark", "gluon", "other", "tau"]
        
        ## taujet SR (MAKE SURE U R NOT VETOING LEPS, INDEED YOU HAVE TO LET ONE LEP GOES THROUGH!)
        taujet_SR = filter(lambda c: c.name=="SR_TAUJET", taujet_config.categories)[0]
        all_events.update(fake_sources(
            [taujet_analysis.ttbar, taujet_analysis.single_top],  taujet_SR, ftypes=FAKE_TAU_SOURCE))

        ## taujet multijet CR
        all_events.update(fake_sources(
            [taujet_analysis.ttbar, taujet_analysis.single_top],  FF_CR_MULTIJET, ftypes=FAKE_TAU_SOURCE))
        
        ## taulep SR
        taulep_SR = filter(lambda c: c.name=="SR_TAULEP", taulep_config.categories)[0]
        all_events.update(fake_sources(
            [taulep_analysis.ttbar, taulep_analysis.single_top], taulep_SR, ftypes=FAKE_TAU_SOURCE))
        
        ## taulep Wjets CR
        all_events.update(fake_sources(
            [taulep_analysis.wlnu], FF_CR_WJETS, ftypes=FAKE_TAU_SOURCE))

        print all_events
        rows = [[""] + ["tau | antitau"]*len(regions)]
        rows += [[fn] for fn in fnames]
        for n, row in enumerate(rows[1:]):
            for rg in regions:
                wrong_taus = 100*(all_events["%s__%s"%(rg, row[0])]["TAU"])/all_events["%s__sum"%rg]["TAU"]
                wrong_antitaus = 100*all_events["%s__%s"%(rg, row[0])]["ANTITAU"]/all_events["%s__sum"%rg]["ANTITAU"]
                vals = "%.1f | %.1f"%(wrong_taus, wrong_antitaus)
                row.append(vals)
                
        print tabulate(rows, headers=regions)        
        with open("fakes_sources.TXT", "a") as ofile:        
            ofile.write("{0}\n\n".format(tabulate(rows, headers=regions)))
            ofile.write("{0}\n\n".format(tabulate(rows, headers=regions, tablefmt="latex")))
        
    ##------------------------------------------------------------------------------------
    ## - - Fake Factors for the corresponding control regions
    ##------------------------------------------------------------------------------------
    cr_ffs = {}
    try:
        log.info("loading FFs from %s"%FFs_ARGS.ffs_cr_cache)
        with open(FFs_ARGS.ffs_cr_cache, "r") as ffs_cr_cache:
            cr_ffs = yaml.load(ffs_cr_cache)
    except Exception, err:
        log.warning("failed to load CR FFs; calculating them on the fly")
        kparams = {
            "template_fields": FFS_TEMPLATE_VARS,
            "template_hist_bins":TAU_PT_BINS,
            "tau_jet_bdt_score_trans_wps": [0.01, 0.02, 0.03],
            "n_charged_tracks": N_CHARGED_TRACKS,
            "cache_file": FFs_ARGS.ffs_cr_cache,
            "subtract_mc": True,
            "antitau": LOOSE_TAU,
            "validation_plots":FFs_ARGS.validation_plots,}

        ffs_workers = []
        # ## taujet
        # ffs_workers += taujet_analysis.ffs_workers(control_regions=[], **kparams)
        
        ## taulep
        ffs_workers += taulep_analysis.ffs_workers(control_regions=[], **kparams)
        
        log.info(
            "************** submitting %i jobs  ************"%len(ffs_workers))
        log.info(
            "***********************************************")
        rand_workers = [ ffs_workers[i] for i in sorted(random.sample(xrange(len(ffs_workers)), min(20, len(ffs_workers) ) ) ) ]
        log.debug(rand_workers)
        log.debug("*"*80)

        pool = multiprocessing.Pool(multiprocessing.cpu_count())
        results = [pool.apply_async(dataset_hists, args=(w,)) for w in ffs_workers]
        hist_sets = []
        for res in results:
            hist_sets += res.get(36000)
        
        cr_ffs = get_cr_ffs(hist_sets, control_regions=FFS_CONTROL_REGIONS, **kparams)

        with open(FFs_ARGS.ffs_cr_cache, "w") as ffs_cr_cache:
            yaml.dump(cr_ffs, ffs_cr_cache)
            
    ## validation plots
    if FFs_ARGS.validation_plots:
        plot_cr_ffs(cr_ffs,
                    pdir=FFs_ARGS.pdir,
                    data_info=taujet_analysis.data.info, 
                    pname="FFs_inclusive_tracks_pT_%s"%FFs_ARGS.ffs_cr_cache.replace(".yml", ""), 
                    formats=[".png", ".pdf", ".eps"])
        
    
    ## fit alpha (aka rQCD)
    if FFs_ARGS.eval_rqcd:
        ##------------------------------------------------------------------------------------
        ## - - calcualte rQCD 
        ## - - we need the histograms per pT and nTracks bin (benefiting from 3D histograms)
        ##------------------------------------------------------------------------------------
        try:
            log.info("loading FFs histograms from %s"%FFs_ARGS.ffs_hists_cache)
            with open(FFs_ARGS.ffs_hists_cache, "r") as ifile:
                combined_ffs_hists = pickle.load(ifile)
        except Exception, err:
            log.warning("failed to load FFs histograms from %s; calculating them on the fly"%FFs_ARGS.ffs_hists_cache)
            combined_ffs_hists = {"taulep": {}, "taujet": {}}

            ## - - set tauID to loose tau 
            tj_cats = copy.deepcopy(TAUJET_TARGET_REGIONS)
            for cat in tj_cats:
                cat.tauid = LOOSE_TAU
                
            taujet_hists = taujet_analysis.hists(
                fields=rQCD_VARS.values(), categories=tj_cats, samples=TAUJET_SAMPLES,
                parallel=True, hist_templates=FIT_HIST_TEMPLATES,)
            combined_ffs_hists["taujet"] = taujet_hists

            ## - - set tauID to loose tau 
            tl_cats = copy.deepcopy(TAULEP_TARGET_REGIONS)
            for cat in tl_cats:
                cat.tauid = LOOSE_TAU
                
            taulep_hists = taulep_analysis.hists(
                fields=rQCD_VARS.values(), categories=tl_cats, samples=TAULEP_SAMPLES,
                parallel=True, hist_templates=FIT_HIST_TEMPLATES,)
            combined_ffs_hists["taulep"] = taulep_hists
            
            ## write the histograms to disk
            with open(FFs_ARGS.ffs_hists_cache, "w") as pfile:
                pickle.dump(combined_ffs_hists, pfile)
        try:
            log.info("loading alphas from %s"%FFs_ARGS.rqcd_cache)
            with open(FFs_ARGS.rqcd_cache, "r") as cfile:
                alphas = yaml.load(cfile)
        except Exception, err:
            log.warning("failed to load alphas from %s; evaluating them on the fly"%FFs_ARGS.rqcd_cache)
            cr_hists = []
            target_hists = []
            ## convert 3D hists to 1D hists with the desired binning
            for analysis in [taujet_analysis, taulep_analysis]:
                channel = analysis.config.channel
                cr_regions = analysis.config.ff_cr_regions
                target_regions = analysis.config.categories

                hsets = prep_ff_hists(combined_ffs_hists[channel],
                                      control_regions=cr_regions, target_regions=target_regions, shape_vars=rQCD_VARS, fitting_bins=TAU_PT_BINS)
                cr_hists += filter(lambda hs: hs.category in [c.name for c in cr_regions], hsets)
                target_hists += filter(lambda hs: hs.category in [t.name for t in target_regions], hsets)

            alphas = fit_alpha(cr_hists, target_hists,
                               fitting_bins=TAU_PT_BINS,
                               shape_vars=rQCD_VARS,
                               cache=FFs_ARGS.rqcd_cache,
                               pdir=FFs_ARGS.pdir,
                               validation_plots=FFs_ARGS.validation_plots)
        if FFs_ARGS.validation_plots:
            tj_regions = [Category_BVETO, Category_SR_TAUJET]
            plot_alpha(
                alphas, cr_ffs, regions=tj_regions, pdir=FFs_ARGS.pdir, formats=[".png", ".pdf", ".eps"], suffix="taujet", data_info=taujet_analysis.data.info, colors=COLORS)

            tl_regions = [Category_SS_TAUEL, Category_SS_TAUMU, Category_SR_TAULEP]
            plot_alpha(
                alphas, cr_ffs, regions=tl_regions, pdir=FFs_ARGS.pdir, formats=[".png", ".pdf", ".eps"], suffix="taulep", data_info=taulep_analysis.data.info, colors=COLORS)
    
end_time = time.time()
elapsed_time = (end_time - start_time)/60.
log.info("\n****************** elapsed time: %0.1f mins ******************"%elapsed_time)
