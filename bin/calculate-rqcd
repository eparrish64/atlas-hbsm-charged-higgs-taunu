#! /usr/bin/env python

"""
* this script is meant for fake factors calculation in some dedicated control regions
* and then combining them in the signal region/other CR regions depending on the composition
* of the jets faking taus (quark or gluon type jets).
"""

## stdlib
import os, sys, time, array, pickle, yaml 
import multiprocessing

## PyPI
import numpy as np
from tabulate import tabulate

# - - - - - - - -  parse ana args (needed before ROOT)
from hpana.cmd import get_ffs_parser 
ffs_parser = get_ffs_parser()
FFs_ARGS = ffs_parser.parse_args()

## local
from hpana.rqcd import fit_alpha, prep_ff_hists, fake_sources, plot_cr_ffs, plot_alpha 
from hpana.variables import rQCD_VARS, FFS_TEMPLATE_VARS, tau_0_jet_width, tau_0_jet_bdt_score_trans
from hpana.categories import FAKE_TAU_SOURCE, FF_CR_MULTIJET, FF_CR_WJETS
from hpana.config import Configuration
from hpana.analysis import Analysis
from hpana.trigger import MULTIJET_TRIGGER
from hpana.samples.fakes import QCD
from hpana import log


# - - - - time it
start_time = time.time()


# - - - - - - - -  set log level
log.setLevel(FFs_ARGS.log)

# - - - - - - - - Speed things up a bit
import ROOT
ROOT.SetSignalPolicy(ROOT.kSignalFast)
ROOT.gROOT.SetBatch(True)
log.info("ROOT is in batch mode")
ROOT.gErrorIgnoreLevel = ROOT.kWarning #<! turn off useless ROOT Info messages (tons of them for Chi2 fit)

##------------------------------------------------------------------------------------
## - - build both taujet and taulep analyses (FF CR s are for different channels)
##------------------------------------------------------------------------------------
taujet_config = Configuration("taujet",
                              mc_campaign="mc16", data_streams=FFs_ARGS.data_streams, db_version=FFs_ARGS.db_version)
taujet_analysis = Analysis(taujet_config, compile_cxx=True)
taujet_analysis.data.blind = False #<! no blinding for FFs calcualtion

taulep_config = Configuration("taulep",
                              mc_campaign="mc16", data_streams=FFs_ARGS.data_streams, db_version=FFs_ARGS.db_version)
taulep_analysis = Analysis(taulep_config, compile_cxx=True)
taulep_analysis.data.blind = False


##------------------------------------------------------------------------------------
## - - consts 
##------------------------------------------------------------------------------------
COLORS = [ROOT.kRed, ROOT.kBlue, ROOT.kBlack, ROOT.kMagenta, ROOT.kOrange, ROOT.kGreen]
LOOSE_TAU = ROOT.TCut("tau_0_jet_bdt_loose==0")
N_CHARGED_TRAKCS = [1, 3] 
TAU_PT_BINS = {
    "1":[30, 35, 40, 45, 50, 60, 75, 90, 105, 120, 140, 160, 200, 300, 3500],
    "3":[30, 35, 40, 50, 75, 100, 150, 200, 3500],
}

## - - - - CR and target selection regions
TAULEP_TARGET_REGIONS = taulep_config.categories
TAUJET_TARGET_REGIONS = taujet_config.categories
TARGET_REGIONS = TAUJET_TARGET_REGIONS + TAULEP_TARGET_REGIONS
FFS_CONTROL_REGIONS = taujet_config.ff_cr_regions + taulep_config.ff_cr_regions


## - - - - hist template for rQCD calculation
FIT_HIST_TEMPLATES = {
    #<! PLS NOTE the tformula order is Z:Y:X and for the binning it's X, Y, Z !
    "tau_0_jet_width":
    ROOT.TH3F("tau_0_p4->Pt():tau_0_n_charged_tracks:tau_0_jet_width_trks_dr04", "tau_0_jet_width", 20, 0, .4, 4, 0, 4, 800, 0, 4000),
    "tau_0_jet_bdt_score_trans":
    ROOT.TH3F("tau_0_p4->Pt():tau_0_n_charged_tracks:tau_0_jet_bdt_score_trans", "tau_0_jet_bdt_score_trans", 50, 0, .5, 4, 0, 4, 800, 0, 4000),
}

## - - - - samples with true tau, lep faking tau and data
TAUJET_SAMPLES = [taujet_analysis.data,]
TAULEP_SAMPLES = [taulep_analysis.data,]

if FFs_ARGS.samples:
    TAUJET_SAMPLES = filter(lambda s: s.name in FFs_ARGS.samples, TAUJET_SAMPLES)
    TAULEP_SAMPLES = filter(lambda s: s.name in FFs_ARGS.samples, TAULEP_SAMPLES)

if __name__=="__main__":
    ##------------------------------------------------------------------------------------
    ## - - Fake tau source 
    ##------------------------------------------------------------------------------------
    if FFs_ARGS.fake_sources:
        all_events = {}
        regions = ["SR_TAUJET", "SR_TAULEP", "FF_CR_MULTIJET", "FF_CR_WJETS"]
        fnames = ["electron", "lquark", "cquark", "bquark", "gluon", "other", "tau"]
        
        ## taujet SR (MAKE SURE U R NOT VETOING LEPS, INDEED YOU HAVE TO LET ONE LEP GOES THROUGH!)
        taujet_SR = filter(lambda c: c.name=="SR_TAUJET", taujet_config.categories)[0]
        all_events.update(fake_sources(
            [taujet_analysis.ttbar, taujet_analysis.single_top],  taujet_SR, ftypes=FAKE_TAU_SOURCE))

        ## taujet multijet CR
        all_events.update(fake_sources(
            [taujet_analysis.ttbar, taujet_analysis.single_top],  FF_CR_MULTIJET, ftypes=FAKE_TAU_SOURCE))
        
        ## taulep SR
        taulep_SR = filter(lambda c: c.name=="SR_TAULEP", taulep_config.categories)[0]
        all_events.update(fake_sources(
            [taulep_analysis.ttbar, taulep_analysis.single_top], taulep_SR, ftypes=FAKE_TAU_SOURCE))
        
        ## taulep Wjets CR
        all_events.update(fake_sources(
            [taulep_analysis.wlnu], FF_CR_WJETS, ftypes=FAKE_TAU_SOURCE))

        print all_events
        rows = [[""] + ["tau | antitau"]*len(regions)]
        rows += [[fn] for fn in fnames]
        for n, row in enumerate(rows[1:]):
            for rg in regions:
                wrong_taus = 100*(all_events["%s__%s"%(rg, row[0])]["TAU"])/all_events["%s__sum"%rg]["TAU"]
                wrong_antitaus = 100*all_events["%s__%s"%(rg, row[0])]["ANTITAU"]/all_events["%s__sum"%rg]["ANTITAU"]
                vals = "%.1f | %.1f"%(wrong_taus, wrong_antitaus)
                row.append(vals)
                
        print tabulate(rows, headers=regions)        
        with open("fakes_sources.TXT", "a") as ofile:        
            ofile.write("{0}\n\n".format(tabulate(rows, headers=regions)))
            ofile.write("{0}\n\n".format(tabulate(rows, headers=regions, tablefmt="latex")))
        
    ##------------------------------------------------------------------------------------
    ## - - Fake Factors for the corresponding control regions
    ##------------------------------------------------------------------------------------
    try:
        log.info("loading FFs from %s"%FFs_ARGS.ffs_cr_cache)
        with open(FFs_ARGS.ffs_cr_cache, "r") as ffs_cr_cache:
            cr_ffs = yaml.load(ffs_cr_cache)
    except Exception, err:
        log.warning("failed to load CR FFs; calculating them on the fly")
        kparams = {
            "template_fields": FFS_TEMPLATE_VARS,
            "template_hist_bins":TAU_PT_BINS,
            "tau_jet_bdt_score_trans_wps": [0.01, 0.02, 0.03],
            "n_charged_tracks": N_CHARGED_TRAKCS,
            "cache_file": FFs_ARGS.ffs_cr_cache,
            "subtract_mc": True,
            "antitau": LOOSE_TAU,
            "validation_plots":FFs_ARGS.validation_plots,}

        ## taujet 
        tj_ffs = taujet_analysis.cache_ffs(control_regions=[], trigger=MULTIJET_TRIGGER, **kparams)

        ## taulep
        tl_ffs = taulep_analysis.cache_ffs(control_regions=[], **kparams)

        cr_ffs = tj_ffs.update(tl_ffs)
        
        with open(FFs_ARGS.ffs_cr_cache, "w") as ffs_cr_cache:
            yaml.dump(cr_ffs, ffs_cr_cache)
            
    ## validation plots
    if FFs_ARGS.validation_plots:
        plot_cr_ffs(cr_ffs,
                    pdir=FFs_ARGS.pdir, pname="FFs_inclusive_tracks_pT_%s.png"%FFs_ARGS.ffs_cr_cache.replace(".yml", ""))
        
    ##------------------------------------------------------------------------------------
    ## - - calcualte rQCD 
    ## - - we need the histograms per pT and nTracks bin (benefiting from 3D histograms)
    ##------------------------------------------------------------------------------------
    try:
        log.info("loading FFs histograms from %s"%FFs_ARGS.ffs_hists_cache)
        with open(FFs_ARGS.ffs_hists_cache, "r") as ifile:
            combined_ffs_hists = pickle.load(ifile)
    except Exception, err:
        log.warning("failed to load FFs histograms from %s; calculating them on the fly"%FFs_ARGS.ffs_hists_cache)
        combined_ffs_hists = {"taulep": {}, "taujet": {}}
        
        taujet_hists = taujet_analysis.hists(
            fields=rQCD_VARS.values(), categories=TAUJET_TARGET_REGIONS, samples=TAUJET_SAMPLES,
            parallel=True, tauid=LOOSE_TAU, hist_templates=FIT_HIST_TEMPLATES,)
        combined_ffs_hists["taujet"] = taujet_hists

        taulep_hists = taulep_analysis.hists(
            fields=rQCD_VARS.values(), categories=TAULEP_TARGET_REGIONS, samples=TAULEP_SAMPLES,
            parallel=True, tauid=LOOSE_TAU, hist_templates=FIT_HIST_TEMPLATES,)
        combined_ffs_hists["taulep"] = taulep_hists
        

        ## write the histograms to disk
        with open(FFs_ARGS.ffs_hists_cache, "w") as pfile:
            pickle.dump(combined_ffs_hists, pfile)
    
    ## fit alpha (aka rQCD)
    if FFs_ARGS.eval_rqcd:
        try:
            log.info("loading alphas from %s"%FFs_ARGS.rqcd_cache)
            with open(FFs_ARGS.rqcd_cache, "r") as cfile:
                alphas = yaml.load(cfile)
        except Exception, err:
            log.warning("failed to load alphas from %s; evaluating them on the fly"%FFs_ARGS.rqcd_cache)
            cr_hists = []
            target_hists = []
            ## convert 3D hists to 1D hists with the desired binning
            for analysis in [taujet_analysis, taulep_analysis]:
                channel = analysis.config.channel
                cr_regions = analysis.config.ff_cr_regions
                target_regions = analysis.config.categories

                hsets = prep_ff_hists(combined_ffs_hists[channel],
                                      control_regions=cr_regions, target_regions=target_regions, shape_vars=rQCD_VARS, fitting_bins=TAU_PT_BINS)
                cr_hists += filter(lambda hs: hs.category in [c.name for c in cr_regions], hsets)
                target_hists += filter(lambda hs: hs.category in [t.name for t in target_regions], hsets)

            alphas = fit_alpha(cr_hists, target_hists,
                               fitting_bins=TAU_PT_BINS,
                               shape_vars=rQCD_VARS,
                               cache=FFs_ARGS.rqcd_cache,
                               pdir=FFs_ARGS.pdir,
                               validation_plots=FFs_ARGS.validation_plots)
        if FFs_ARGS.validation_plots:
            plot_alpha(alphas, cr_ffs, regions=TARGET_REGIONS, pdir=FFs_ARGS.pdir)
    
end_time = time.time()
elapsed_time = (end_time - start_time)/60.
log.info("\n****************** elapsed time: %0.1f mins ******************"%elapsed_time)
