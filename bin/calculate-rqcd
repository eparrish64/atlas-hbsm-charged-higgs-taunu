#! /usr/bin/env python

"""
* this script is meant for fake factors calculation in some dedicated control regions
* and then combining them in the signal region/other CR regions depending on the composition
* of the jets faking taus (quark or gluon type jets).
"""

## stdlib
import os, sys, time, array, pickle, copy, random
import multiprocessing


## PyPI
import numpy as np
from tabulate import tabulate
import yaml

# - - - - - - - -  parse ana args (needed before ROOT)
from hpana.cmd import get_ffs_parser 
ffs_parser = get_ffs_parser()
FFs_ARGS = ffs_parser.parse_args()

## local
from hpana.rqcd import get_cr_ffs, fit_alpha, prep_ff_hists, fake_sources, plot_cr_ffs, plot_alpha, correct_upsilon 
from hpana.variables import rQCD_VARS, FFS_TEMPLATE_VARS, tau_0_jet_width, tau_0_jet_rnn_score_trans, tau_0_upsilon
from hpana.categories import (
    ANTI_TAU,
    TAUID_MEDIUM,
    FAKE_TAU_SOURCE,
    FF_CR_MULTIJET,
    FF_CR_WJETS,
    Category_BVETO,
    Category_SR_TAUJET,
    Category_SR_TAULEP,
    Category_TAUEL_BVETO,
    Category_TAUMU_BVETO,
    Category_SS_TAUEL,
    Category_SS_TAUMU,
    Category_BVETO_MT100,
    Category_TAUJET_BASE,
    Category_TAULEP_BASE,)
    
from hpana.dataset_hists import dataset_hists
from hpana.config import Configuration
from hpana.analysis import Analysis
from hpana.samples.fakes import QCD
from hpana import log


# - - - - time it
start_time = time.time()


# - - - - - - - -  set log level
log.setLevel(FFs_ARGS.log)

# - - - - - - - - Speed things up a bit
import ROOT
ROOT.SetSignalPolicy(ROOT.kSignalFast)
ROOT.gROOT.SetBatch(True)
ROOT.gROOT.SetStyle("ATLAS")
log.debug("ROOT is in batch mode")
ROOT.gErrorIgnoreLevel = ROOT.kWarning #<! turn off useless ROOT Info messages (tons of them for Chi2 fit)

##------------------------------------------------------------------------------------
## - - build both taujet and taulep analyses (FF CR s are for different channels)
##------------------------------------------------------------------------------------
taujet_config = Configuration(
    "taujet", mc_campaign="mc16", data_streams=FFs_ARGS.data_streams, db_version=FFs_ARGS.db_version)
taujet_analysis = Analysis(taujet_config, compile_cxx=True)
taujet_analysis.data.blind = False #<! no blinding for FFs calculation

taulep_config = Configuration(
    "taulep", mc_campaign="mc16", data_streams=FFs_ARGS.data_streams, db_version=FFs_ARGS.db_version)
taulep_analysis = Analysis(taulep_config, compile_cxx=True)
taulep_analysis.data.blind = False


##------------------------------------------------------------------------------------
## - - consts 
##------------------------------------------------------------------------------------
COLORS = [ROOT.kRed, ROOT.kBlue, ROOT.kBlack, ROOT.kMagenta, ROOT.kOrange, ROOT.kGreen]
LOOSE_ANTITAU = ROOT.TCut("tau_0_jet_rnn_loose==0")
N_CHARGED_TRACKS = [1, 3] 
TAU_PT_BINS = {
    "1":[30, 35, 40, 45, 50, 60, 80, 100, 200, 3500],
    "3":[30, 35, 40, 60, 80, 100, 3500],
}

## - - - - CR and target selection regions
TAULEP_TARGET_REGIONS = taulep_config.categories + taulep_config.ff_cr_regions + taulep_config.clf_regions + taulep_config.met_trigeff_regions
TAUJET_TARGET_REGIONS = taujet_config.categories + taujet_config.ff_cr_regions + taujet_config.clf_regions
TARGET_REGIONS = TAUJET_TARGET_REGIONS + TAULEP_TARGET_REGIONS
FFS_CONTROL_REGIONS = taulep_config.ff_cr_regions + taujet_config.ff_cr_regions 


## - - - - hist template for rQCD calculation
FIT_HIST_TEMPLATES = {
    #<! PLS NOTE the tformula order is Z:Y:X and for the binning it's X, Y, Z !
    "tau_0_jet_width":
    ROOT.TH3F("tau_0_p4->Pt():tau_0_n_charged_tracks:tau_0_jet_width_trks_dr04", "tau_0_jet_width", 20, 0, .4, 4, 0, 4, 800, 0, 4000),
    "tau_0_jet_rnn_score_trans":
    ROOT.TH3F("tau_0_p4->Pt():tau_0_n_charged_tracks:tau_0_jet_rnn_score_trans", "tau_0_jet_rnn_score_trans", 50, 0, .5, 4, 0, 4, 800, 0, 4000),
}

## - - - - samples with true tau, lep faking tau and data
TAUJET_SAMPLES = [taujet_analysis.data,]
TAULEP_SAMPLES = [taulep_analysis.data,]

if FFs_ARGS.samples:
    TAUJET_SAMPLES = filter(lambda s: s.name in FFs_ARGS.samples, TAUJET_SAMPLES)
    TAULEP_SAMPLES = filter(lambda s: s.name in FFs_ARGS.samples, TAULEP_SAMPLES)

if __name__=="__main__":
    ##------------------------------------------------------------------------------------
    ## - - Fake tau source 
    ##------------------------------------------------------------------------------------
    if FFs_ARGS.fake_sources:
        all_events = {}
        regions = ["SR_TAUJET", "SR_TAULEP", "FF_CR_MULTIJET", "FF_CR_WJETS"]
        fnames = ["electron", "lquark", "cquark", "bquark", "gluon", "other", "tau"]

        ## taujet SR (MAKE SURE U R NOT VETOING LEPS, INDEED YOU HAVE TO LET ONE LEP GOES THROUGH!)
        taujet_SR = filter(lambda c: c.name=="SR_TAUJET", taujet_config.categories)[0]
        all_events.update(fake_sources(
            [taujet_analysis.ttbar, taujet_analysis.single_top],  taujet_SR, ftypes=FAKE_TAU_SOURCE))

        ## taujet multijet CR
        all_events.update(fake_sources(
            [taujet_analysis.ttbar, taujet_analysis.single_top],  FF_CR_MULTIJET, ftypes=FAKE_TAU_SOURCE))
        
        ## taulep SR
        taulep_SR = filter(lambda c: c.name=="SR_TAULEP", taulep_config.categories)[0]
        all_events.update(fake_sources(
            [taulep_analysis.ttbar, taulep_analysis.single_top], taulep_SR, ftypes=FAKE_TAU_SOURCE))
        
        ## taulep Wjets CR
        all_events.update(fake_sources(
            [taulep_analysis.wlnu], FF_CR_WJETS, ftypes=FAKE_TAU_SOURCE))

        print all_events
        rows = [[""] + ["tau | antitau"]*len(regions)]
        rows += [[fn] for fn in fnames]
        for n, row in enumerate(rows[1:]):
            for rg in regions:
                wrong_taus = 100*(all_events["%s__%s"%(rg, row[0])]["TAU"])/all_events["%s__sum"%rg]["TAU"]
                wrong_antitaus = 100*all_events["%s__%s"%(rg, row[0])]["ANTITAU"]/all_events["%s__sum"%rg]["ANTITAU"]
                vals = "%.1f | %.1f"%(wrong_taus, wrong_antitaus)
                row.append(vals)
                
        print tabulate(rows, headers=regions)        
        with open("fakes_sources.TXT", "a") as ofile:        
            ofile.write("{0}\n\n".format(tabulate(rows, headers=regions)))
            ofile.write("{0}\n\n".format(tabulate(rows, headers=regions, tablefmt="latex")))

    ##------------------------------------------------------------------------------------
    ## - - Correcting tau polarization observable (different shape for anti-tau and tau)
    ##------------------------------------------------------------------------------------
    if FFs_ARGS.correct_upsilon:
        hists = []
        cr_regions = []
        tau_0_upsilon.binning = (3000, -1, 2) #<! @NOTE: BINNING MATTERS 

        ## get tau and anti-tau distributions 
        for ana in [taujet_analysis, taulep_analysis]:
            cr = ana.config.ff_cr_regions[0]
            cr_regions += [cr]
            samples = filter(lambda s: s.name=="Data", ana.samples) #<! no need to include MC
            tau_cr = copy.deepcopy(cr)
            tau_cr.tauid = TAUID_MEDIUM + ROOT.TCut("tau_0_n_charged_tracks==1") #<! 1-prong only
            tau_cr.name = tau_cr.name +"_TAU"

            antitau_cr = copy.deepcopy(cr)
            antitau_cr.tauid = ANTI_TAU + ROOT.TCut("tau_0_n_charged_tracks==1")
            antitau_cr.name = antitau_cr.name +"_ANTITAU"

            hists += ana.hists(categories=[tau_cr, antitau_cr], samples=samples, fields=[tau_0_upsilon])
        
        ## build the correction macro and produce validation plots 
        correct_upsilon(hists, cr_regions, cache=FFs_ARGS.upsilon_correction_cache, outdir=FFs_ARGS.pdir)


    ##------------------------------------------------------------------------------------
    ## - - Fake Factors for the corresponding control regions
    ##------------------------------------------------------------------------------------
    cr_ffs = {}
    try:
        log.info("loading FFs from %s"%FFs_ARGS.ffs_cr_cache)
        with open(FFs_ARGS.ffs_cr_cache, "r") as ffs_cr_cache:
            cr_ffs = yaml.load(ffs_cr_cache)
    except Exception, err:
        log.warning("failed to load CR FFs; calculating them on the fly")
        kparams = {
            "template_fields": FFS_TEMPLATE_VARS,
            "template_hist_bins":TAU_PT_BINS,
            "tau_jet_rnn_score_trans_wps": {"NOMINAL":0.01, "RNN_1up": 0.01, "RNN_1down": 0.01},
            "n_charged_tracks": N_CHARGED_TRACKS,
            "cache_file": FFs_ARGS.ffs_cr_cache,
            "subtract_mc": True,
            "antitau": LOOSE_ANTITAU,
            "validation_plots":FFs_ARGS.validation_plots,}

        ffs_workers = []
        ## taujet
        ffs_workers += taujet_analysis.ffs_workers(control_regions=[], **kparams)
        
        ## taulep
        ffs_workers += taulep_analysis.ffs_workers(control_regions=[], **kparams)
        
        log.info("************** submitting %i jobs  ************"%len(ffs_workers))
        log.info( "***********************************************")
        rand_workers = [ ffs_workers[i] for i in sorted(random.sample(xrange(len(ffs_workers)), min(50, len(ffs_workers) ) ) ) ]
        log.info("Checking some random workers ... ")
        for w in rand_workers:
            print w
            print "--"*70


        pool = multiprocessing.Pool(multiprocessing.cpu_count())
        results = [pool.apply_async(dataset_hists, args=(w,)) for w in ffs_workers]
        hist_sets = []
        for res in results:
            hist_sets += res.get(36000)
                    
        cr_ffs = get_cr_ffs(hist_sets, control_regions=FFS_CONTROL_REGIONS, **kparams)

        with open(FFs_ARGS.ffs_cr_cache, "w") as ffs_cr_cache:
            yaml.dump(cr_ffs, ffs_cr_cache)
            
    ## validation plots
    if FFs_ARGS.validation_plots:
        plot_cr_ffs(cr_ffs,
                    pdir=FFs_ARGS.pdir,
                    data_info=taujet_analysis.data.info, 
                    pname="FFs_inclusive_tracks_pT_%s"%FFs_ARGS.ffs_cr_cache.replace(".yml", ""), 
                    formats=[".png"])
        
    
    ## fit alpha (aka rQCD)
    if FFs_ARGS.eval_rqcd:
        ##------------------------------------------------------------------------------------
        ## - - calcualte rQCD 
        ## - - we need the histograms per pT and nTracks bin (benefiting from 3D histograms)
        ##------------------------------------------------------------------------------------
        try:
            log.info("loading FFs histograms from %s"%FFs_ARGS.ffs_hists_cache)
            with open(FFs_ARGS.ffs_hists_cache, "r") as ifile:
                combined_ffs_hists = pickle.load(ifile)
        except Exception, err:
            log.warning("failed to load FFs histograms from %s; calculating them on the fly"%FFs_ARGS.ffs_hists_cache)
            combined_ffs_hists = {"taulep": {}, "taujet": {}}

            ## - - set tauID to loose tau 
            tj_cats = copy.deepcopy(TAUJET_TARGET_REGIONS)
            for cat in tj_cats:
                cat.tauid = ANTI_TAU
                
            taujet_hists = taujet_analysis.hists(
                fields=rQCD_VARS.values(), categories=tj_cats, samples=TAUJET_SAMPLES,
                parallel=True, hist_templates=FIT_HIST_TEMPLATES,)
            combined_ffs_hists["taujet"] = taujet_hists

            ## - - set tauID to loose tau 
            tl_cats = copy.deepcopy(TAULEP_TARGET_REGIONS)
            for cat in tl_cats:
                cat.tauid = ANTI_TAU
                
            taulep_hists = taulep_analysis.hists(
                fields=rQCD_VARS.values(), categories=tl_cats, samples=TAULEP_SAMPLES,
                parallel=True, hist_templates=FIT_HIST_TEMPLATES,)
            combined_ffs_hists["taulep"] = taulep_hists
            
            ## write the histograms to disk
            with open(FFs_ARGS.ffs_hists_cache, "w") as pfile:
                pickle.dump(combined_ffs_hists, pfile)
        try:
            log.info("loading alphas from %s"%FFs_ARGS.rqcd_cache)
            with open(FFs_ARGS.rqcd_cache, "r") as cfile:
                alphas = yaml.load(cfile)
        except Exception, err:
            log.warning("failed to load alphas from %s; evaluating them on the fly"%FFs_ARGS.rqcd_cache)
            cr_hists = []
            target_hists = []
            ## convert 3D hists to 1D hists with the desired binning
            for analysis in [taujet_analysis, taulep_analysis]:
                channel = analysis.config.channel
                cr_regions = analysis.config.ff_cr_regions
                if analysis.config.channel=="taulep":
                    target_regions = TAULEP_TARGET_REGIONS 
                else:
                    target_regions = TAUJET_TARGET_REGIONS

                hsets = prep_ff_hists(combined_ffs_hists[channel],
                                      control_regions=cr_regions, target_regions=target_regions, shape_vars=rQCD_VARS, fitting_bins=TAU_PT_BINS)
                cr_hists += filter(lambda hs: hs.category in [c.name for c in cr_regions], hsets)
                target_hists += filter(lambda hs: hs.category in [t.name for t in target_regions], hsets)

            alphas = fit_alpha(cr_hists, target_hists,TARGET_REGIONS,
                               fitting_bins=TAU_PT_BINS,
                               shape_vars=rQCD_VARS,
                               cache=FFs_ARGS.rqcd_cache,
                               pdir=FFs_ARGS.pdir,
                               validation_plots=FFs_ARGS.validation_plots)
        if FFs_ARGS.validation_plots:
            tj_regions = [Category_BVETO, Category_SR_TAUJET, Category_TAUJET_BASE]
            plot_alpha(
                alphas, cr_ffs, regions=tj_regions, pdir=FFs_ARGS.pdir, formats=[".png"], suffix="taujet", data_info=taujet_analysis.data.info, colors=COLORS)

            tl_regions = [Category_SS_TAUEL, Category_SS_TAUMU, Category_SR_TAULEP]
            plot_alpha(
                alphas, cr_ffs, regions=tl_regions, pdir=FFs_ARGS.pdir, formats=[".png"], suffix="taulep", data_info=taulep_analysis.data.info, colors=COLORS)
    
end_time = time.time()
elapsed_time = (end_time - start_time)/60.
log.info("\n****************** elapsed time: %0.1f mins ******************"%elapsed_time)
