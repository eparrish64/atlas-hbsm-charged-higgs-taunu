#!/usr/bin/env python
"""
* This script is for producing final analysis plots.
* input is a ROOT TFile containing all the kinemtatics
* of different samples for  different regions(CR / SR).
* output is a dir containig all the plots.
"""

# stdl-lib
import sys, os
import multiprocessing 
from collections import OrderedDict

# - - - - - - - - - parse plot args (needed before ROOT)
from hpana.cmd import get_plotting_parser
plotting_parser = get_plotting_parser()
PLOTTING_ARGS = plotting_parser.parse_args()

## local 
from hpana.plotting import draw
from hpana.analysis import Analysis
from hpana.config import Configuration
from hpana.cluster.parallel import run_pool, Job
from hpana.variables import BDT_SCORES

# - - - - - - - -  set log level
from hpana import log
log.setLevel(PLOTTING_ARGS.log)

# - - - - - - - - Speed things up a bit
import ROOT
ROOT.SetSignalPolicy(ROOT.kSignalFast)
ROOT.gROOT.SetBatch(True)
ROOT.gROOT.SetStyle("ATLAS")
log.info("ROOT is in batch mode")

# - - - - - - - - build analysis main configuration object
config = Configuration(
    PLOTTING_ARGS.channel,
    year=PLOTTING_ARGS.year,
    data_streams=PLOTTING_ARGS.data_streams,
    mc_campaign=PLOTTING_ARGS.mc_campaign,
    db_version=PLOTTING_ARGS.db_version)

# - - - - - - - - instantiate the analysis
analysis = Analysis(config)

backgrounds = analysis.backgrounds
signals = analysis.get_signals(masses=[80, 160, 400, 2000])
data = analysis.data

# - - - - - - - - some checks on cmd args
if PLOTTING_ARGS.fields:
    fields = filter(lambda v: v.name in PLOTTING_ARGS.fields , config.variables+BDT_SCORES[PLOTTING_ARGS.channel])
else:
    fields = config.variables

if PLOTTING_ARGS.categories:
    categories = filter(
        lambda c: c.name in PLOTTING_ARGS.categories, config.categories+config.ff_cr_regions)
else:
    categories = config.categories

## systematics
all_systematics = config.systematics[:]  # <! common systematics
all_systematics += analysis.qcd.systematics  # <! QCD fakes only
if PLOTTING_ARGS.systematics:
    systematics = filter(
        lambda s: s.name in PLOTTING_ARGS.systematics, all_systematics)
elif PLOTTING_ARGS.systs:
    systematics = all_systematics
else:
    systematics = config.systematics[:1] #<! NOMINAL

if PLOTTING_ARGS.no_data:
    data = None

## draw parameters 
params = {
    "hists_file":PLOTTING_ARGS.hists_file,
    "backgrounds":backgrounds,
    "data":data,
    "signals":signals,
    "signal_scale":1,
    "systematics":systematics,
    "output_dir":PLOTTING_ARGS.pdir,
    "logy":PLOTTING_ARGS.logy,
    "logx":False,
    "show_ratio":True,
    "show_pvalue":False,
    "error_bars":True,
    "bin_optimization":False,
    "scale_sig_to_bkg_sum":True,
    "output_formats": PLOTTING_ARGS.fmt,
}

## setup the output directory for the plots
if not os.path.isdir(params["output_dir"]):
    os.system("mkdir -p %s"%params["output_dir"])

jobs = []
## draw plots
for var in fields:
    jparams = dict(params) #<! defensive copy 

    ##@FIXME check if it's a classification score
    m_range = var.name.split("_")[-1].split("to")
    if len(m_range) > 1:
        masses = [int(m) for m in m_range]
        signals = analysis.get_signals(masses=masses)
        jparams["signals"] = signals

    for cat in categories:
        ## signals are very tiny in control regions --> drop them from plots
        if not "SR_" in cat.name:
            jparams["signals"] = []

        jobs += [Job(draw, var, cat, **jparams)]
run_pool(jobs, n_jobs=-1)
