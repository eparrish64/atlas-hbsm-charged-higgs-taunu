#! /usr/bin/env python

"""
* This script provides functionalities for evaluating MET trigger efficiency. 
* The Emiss trigger is not well described in simulation. The strategy for the treatment of the Emiss trigger in
* simulation is to derive the trigger efficiency from data in bins of offline Emiss. The binned Emiss-dependent
* efficiency is transformed into a continuous efficiency by fitting it to the error function. This is done to
* remove bias caused by the binning. Simulated events are weighted using the efficiency curve, based on
* the offline Emiss in the event.
* EFF =  (event selections + given trigger)/(event selections)
"""

## stdlib
import os, sys, time, array, pickle, yaml 
import multiprocessing

## parse args (needed before ROOT)
from hpana.cmd import get_trig_eff_parser
eff_parser = get_trig_eff_parser()
TRIG_EFF_ARGS = eff_parser.parse_args()


## local
from hpana.config import Configuration
from hpana.analysis import Analysis
from hpana.categories import MET_TRIG_EFF_CRs
from hpana.variables import met_et as MET_ET
from hpana.trigger import MET_TRIGGERS
from hpana.dataset_hists import dataset_hists
from hpana.cluster.parallel import close_pool
from hpana.plotting.plot import label_plot
from hpana import log


## set log level
log.setLevel(TRIG_EFF_ARGS.log)

## Speed things up a bit
import ROOT
ROOT.SetSignalPolicy(ROOT.kSignalFast)
ROOT.gROOT.SetBatch(True)
ROOT.gROOT.SetStyle("ATLAS")
log.debug("ROOT is in batch mode")
ROOT.gErrorIgnoreLevel = ROOT.kWarning #<! turn off useless ROOT Info messages
ROOT.Math.MinimizerOptions.SetDefaultMinimizer("Minuit2")


##------------------------------------------------------------------------------------
## - - consts
##------------------------------------------------------------------------------------
ERR_FUNC_STR = "{0}*(1 + TMath::Erf((met_et - {1})/{2}))+{3}" #<! @NOTE KEEP x FOR DIRECT PLOTTING ROOT CAN"T HANDLE ANYTHING ELSE
MET_ET.bins = range(0, 200, 20) + range(200, 400, 50)
COLORS = [ROOT.kRed, ROOT.kBlue, ROOT.kGreen, ROOT.kMagenta, ROOT.kOrange, ROOT.kYellow]

## - - update lumi blocks
config = Configuration("taulep", data_streams=TRIG_EFF_ARGS.data_streams, mc_campaign="mc16", db_version=TRIG_EFF_ARGS.db_version)
analysis = Analysis(config)
for y, trig in MET_TRIGGERS.iteritems():
    for k in trig.keys():
        runs = MET_TRIGGERS[y][k]["RUNS"]
        dlumi = MET_TRIGGERS[y][k]["LUMI"]
        tlumi = analysis.data.get_lumi_block(*runs)/1000
        if tlumi != dlumi:
            log.warning("updating lumi block ({0}, {1}); default: {2} | calculated: {3}".format(runs[0], runs[1], dlumi, tlumi))
            MET_TRIGGERS[y][k]["LUMI"] = tlumi

##------------------------------------------------------------------------------------
## - - build the taulep analysis (run only on relevant streams) 
##------------------------------------------------------------------------------------
def get_trig_hists(triggers=MET_TRIGGERS,
                   categories=MET_TRIG_EFF_CRs,
                   db_version=TRIG_EFF_ARGS.db_version,
                   data_streams=TRIG_EFF_ARGS.data_streams,
                   hists_cache=TRIG_EFF_ARGS.hists_cache,
                   parallel=TRIG_EFF_ARGS.parallel,
                   dry_run=TRIG_EFF_ARGS.dry_run,
                   ncpu=TRIG_EFF_ARGS.ncpu):
    """
    Given a dictionary of triggers, produce histograms with and without trigger and save their ratio.
    """
    update_cache = True
    ratio_hists = {}
    hists = []
    if hists_cache and os.path.isfile(hists_cache):
        log.info("loading hists from %s"%hists_cache)
        update_cache = False
        with open(hists_cache, "r") as cfile:
            ratio_hists = pickle.load(cfile)
            if (not isinstance(ratio_hists, dict) or not ratio_hists):
                update_cache = True
                log.info("can't load hists from %s!; calculating them on the fly"%hists_cache)
            else:    
                for i, ds in enumerate(data_streams):
                    if not ds in ratio_hists:
                        update_cache = True
                        
    if update_cache:
        workers = []
        for year, trig_dict in triggers.iteritems():
            if not year in data_streams:
                continue
            config = Configuration("taulep", data_streams=(year,), mc_campaign="mc16", db_version=db_version)
            analysis = Analysis(config, compile_cxx=True)
            samples = [analysis.data]

            """
            ## since we want to vary the tauid (already included in MET_TRIG_EFF_CRs),
            ## we pass global tauid=ROOT.TCut("1>0").
            """
            for trigger, info in trig_dict.iteritems():
                workers_with_trigger = analysis.workers(
                    channel="taulep", fields=[MET_ET], categories=categories, samples=samples,
                    trigger=info["TRIGGER"], tauid=ROOT.TCut(""))
                for wt in workers_with_trigger:
                    wt.name = "%s.%s.%s"%(wt.name, year, trigger)
                    workers.append(wt)
                    
                workers_without_trigger = analysis.workers(
                    channel="taulep", fields=[MET_ET], categories=categories, samples=samples,
                    trigger=info["NO_TRIGGER"], tauid=ROOT.TCut(""))
                for wto in workers_without_trigger:
                    wto.name = "%s.%s.%s.NO_TRIGGER"%(wto.name, year, trigger)
                    workers.append(wto)
                    
        if dry_run:
            log.info(workers)
            return 
        if parallel:
            log.info(
                "************** submitting %i jobs  ************"%len(workers))
            log.info(
                "***********************************************")

            pool = multiprocessing.Pool(ncpu)
            results = [pool.apply_async(dataset_hists, (wk,)) for wk in workers]
            # - - close the pool
            close_pool(pool)
            for res in results:
                hists += res.get(36000) #<! without the timeout this blocking call ignores all signals.
        else:
            for w in workers:
                hists += dataset_hists(w)
        ## - - now get the selection+trig/selection histogram
        for year, trig_dict in triggers.iteritems():
            if not year in data_streams:
                continue
            yhists = filter(lambda hs: year in hs.name, hists)
            ratio_hists[year] = {}
            for trigger in trig_dict.keys():
                ratio_hists[year][trigger] = {}
                for category in categories:
                    hs_cat = filter(lambda hs: hs.category==category.name, yhists)
                    hset_trig = filter(lambda hs: hs.name.endswith(trigger), hs_cat)
                    hset_no_trig = filter(lambda hs: hs.name.endswith("%s.NO_TRIGGER"%trigger), hs_cat)

                    hist_trig = reduce(lambda h1, h2: h1+h2, [hs.hist for hs in hset_trig])
                    hist_no_trig = reduce(lambda h1, h2: h1+h2, [hs.hist for hs in hset_no_trig])
                    
                    log.info("***** year: %s; category: %s; trigger: %s *****"%(year, category.name, trigger))
                    log.info("***** category+trigger: %i; category: %i *****"%(
                        hist_trig.Integral(0, -1), hist_no_trig.Integral(0, -1)))
                    
                    assert (hist_trig and hist_no_trig), "couldn't retrieve hists for %s"%category.name

                    ## The error per bin will be computed as sqrt(sum of squares of weight) for each bin.
                    hist_trig.Sumw2()
                    hist_no_trig.Sumw2()
                    hist_trig.Divide(hist_no_trig)
                    ratio_hists[year][trigger][category.name] = hist_trig
                    
        ## cache them
        log.info("updating met trig eff hists cache")
        if os.path.isfile(hists_cache):
            os.system("rm %s"%hists_cache)
        if not hists_cache:
            hist_cache = "met_trig_HISTS.pkl"
        with open(hists_cache, "w") as hfile:
            pickle.dump(ratio_hists, hfile)
            
    return ratio_hists

##------------------------------------------------------------------------------------
## - - fit error function to the histograms
##------------------------------------------------------------------------------------
def fit_eff(eff_hists,
            fit_cache=TRIG_EFF_ARGS.fit_cache,
            num_params=4):
    """

    """
    
    ## - - first let's get the total lumi 
    total_lumi = 0
    for y, trgs in eff_hists.iteritems():
        for trg in trgs:
            total_lumi += MET_TRIGGERS[y][trg]["LUMI"]
            
    ## - - do the fit per trigger per variation
    fit_params  = {}
    fit_funcs = {}
    years = sorted(eff_hists.keys())
    for year, triggers in eff_hists.iteritems():
        fit_funcs[year] = {}
        fit_params[year] = {}
        for trigger, variations in triggers.iteritems():
            lumi = MET_TRIGGERS[year][trigger]["LUMI"]
            fit_funcs[year][trigger] = {}
            fit_params[year][trigger] = {}
            for variation, hist in variations.iteritems():
                if not variation in fit_params:
                    fit_params[year][trigger][variation] = ""
                log.info("performing error function fit for %s trigger & %s region"%(trigger, variation))

                ## - - initialize the function with some reasonable parameters 
                err_function = ROOT.TF1("erf", "[0]*(1 + TMath::Erf((x-[1])/[2]))+[3]", 0, 500)
                err_function.SetParameters(0.5, 100, 50, 0)
                
                ## - - fit and retrieve the function 
                hist.Fit(err_function, "EM")
                fit_func = hist.GetFunction("erf")
                params = [fit_func.GetParameter(n) for n in range(num_params)]
                fit_params[year][trigger][variation] = "(%s)"%ERR_FUNC_STR.format(*params)
                fit_funcs[year][trigger][variation] = (hist, fit_func)

    if fit_cache:
        ## efficiency per year
        with open(fit_cache, "w") as cfile:
            index = 1000
            istring = "float metTrigEff(float met_et, int variation_index, int run_number){\n"
            cfile.write(istring)
            for n, variation in enumerate(MET_TRIG_EFF_CRs):
                cfile.write("\t //! variation: %s\n"%variation.name)
                cfile.write("\t if(variation_index==%i){\n"%(index+n))
                ## efficiency per year    
                for year in years:
                    y_triggers = MET_TRIGGERS[year].keys()
                    year_lumi = sum([MET_TRIGGERS[year][tr]["LUMI"] for tr in y_triggers])
                    rl = min([MET_TRIGGERS[year][tr]["RUNS"][0] for tr in y_triggers])
                    rh = max([MET_TRIGGERS[year][tr]["RUNS"][1] for tr in y_triggers])

                    ## weight periods
                    y_eff = [] 
                    for y_trig in y_triggers:
                        p_lumi = MET_TRIGGERS[year][y_trig]["LUMI"]
                        y_eff += ["%0.4f * (%s)"%(p_lumi/year_lumi, fit_params[year][y_trig][variation.name])]

                    cfile.write("\t\t // year: %s \n"%year)
                    cfile.write("\t\t if(run_number >= %i && run_number <= %i){\n"%(rl, rh))
                    cfile.write("\t\t\t return %s;"%(" + ".join(y_eff) ) )
                    cfile.write("\n\t\t }\n")
                cfile.write("\n\t\t else return 0;\n}\n\n")
            cfile.write("\t\t else return 1.; \n\t}\n")

        ## overall efficiency
        with open(fit_cache, "a") as cfile:
            index = 1000
            istring = "\n\n// total efficiency (lumi weighted) \nfloat metTrigEff(float met_et, int variation_index){\n"
            cfile.write(istring)
            for n, variation in enumerate(MET_TRIG_EFF_CRs):
                cfile.write("\t //! variation: %s\n"%variation.name)
                cfile.write("\t if(variation_index==%i){\n"%(index+n))
                ## efficiency per year    
                tot_eff = []
                for year in years:
                    for trigger in MET_TRIGGERS[year].keys():
                        lumi = MET_TRIGGERS[year][trigger]["LUMI"]
                        tot_eff += ["%0.4f * (%s)"%(lumi/total_lumi, fit_params[year][trigger][variation.name])]
                cfile.write("\t\t return %s;"%("+".join(tot_eff)))
                cfile.write("\n\t }\n\n")
            cfile.write("\n\t else return 0;\n}\n")

    return fit_funcs, fit_params

##------------------------------------------------------------------------------------
## - - plot fit functions 
##------------------------------------------------------------------------------------
def draw_fits(fit_funcs, fit_params, 
    pdir=TRIG_EFF_ARGS.pdir, overlay_syst=True, combined_fit=True, formats=[".png",".pdf", ".eps"]):
    """ Given a dict of hists, fit funcs draw them 
    """
    os.system("mkdir -p %s"%pdir)
    canvas = ROOT.TCanvas("c", "c", 800, 700)
    for year, fits in fit_funcs.iteritems():
        triggers = fits.keys()
        variations = filter(lambda var: var.name in fit_funcs[year][triggers[0]].keys(), MET_TRIG_EFF_CRs)
        for trigger in triggers:
            lumi = MET_TRIGGERS[year][trigger]["LUMI"]
            legend = ROOT.TLegend(0.5, 0.2, 0.9, 0.45)
            legend.SetNColumns(2)
            lables = label_plot(canvas, category=trigger, data_info="#int L dt = %0.2f fb^{-1} (%s)"%(lumi, year), textsize=18)    

            for n, variation in enumerate(variations):
                hist, fit_func = fits[trigger][variation.name]
                hist.SetMarkerSize(2)
                hist.SetMarkerColor(ROOT.kMagenta)
                fit_func.SetMarkerColor(COLORS[n])
                fit_func.SetMarkerSize(1)
                fit_func.SetMarkerStyle(21+n)
                    
                if n==0:
                    hist.GetXaxis().SetTitle(MET_ET.title)
                    hist.GetYaxis().SetTitle("E^{mis}_{T} Trigger Efficiency")
                    hist.Draw("E1")
                    fit_func.Draw("PSAME")
                    for label in lables:
                        label.Draw("SAME")
                if overlay_syst:    
                    fit_func.Draw("PSAME")
                    legend.AddEntry(fit_func, variation.label, "LP")
                else:
                    hist.GetXaxis().SetTitle(MET_ET.title)
                    hist.GetYaxis().SetTitle("E^{mis}_{T} Trigger Efficiency")
                    hist.Draw("PE1")
                    fit_func.Draw("P SAME")
                    legend.AddEntry(fit_func, variation.label, "LP")

                    legend.Draw("SAME")
                    outname = "%s/MET_trig_eff%s_%s_%s"%(pdir, year, variation.name, trigger)
                    log.info("Saving %s"%outname)
                    for fmt in formats:
                        canvas.Print(outname+fmt)
                    legend.Clear()
                    canvas.Clear()
            if overlay_syst:
                legend.Draw("SAME")
                os.system("mkdir -p %s"%pdir)
                outname = "%s/MET_trig_eff%s_%s"%(pdir, year, trigger)
                log.info("Saving %s"%outname)
                for fmt in formats:
                    canvas.Print(outname+fmt)
                legend.Clear()
                canvas.Clear()

    if combined_fit:
        # canvas = ROOT.TCanvas("cnew", "cnew", 800, 700)

        total_lumi = 0
        for y, trgs in MET_TRIGGERS.iteritems():
            for trg in trgs:
                total_lumi += MET_TRIGGERS[y][trg]["LUMI"]
            
        for variation in MET_TRIG_EFF_CRs:
            legend = ROOT.TLegend(0.6, 0.2, 0.9, 0.4)
            legend.SetNColumns(2)

            ## efficiency per year
            y_fits = []   
            years =  MET_TRIGGERS.keys()
            for year in years:
                y_params = []
                triggers = MET_TRIGGERS[year].keys()
                year_lumi = sum([MET_TRIGGERS[year][tr]["LUMI"] for tr in triggers])
                for trigger in triggers:
                    lumi = MET_TRIGGERS[year][trigger]["LUMI"]
                    y_params += ["%0.4f * (%s)"%(lumi/year_lumi, fit_params[year][trigger][variation.name].replace("met_et", "x"))]

                ## @NOTE have to keep them in the scope for plotting 
                y_fit = ROOT.TF1("fit_com_%s"%year, " + ".join(y_params), 0, 500)
                y_fits+= [y_fit]

            cnt = 0
            for yf, yr in zip(y_fits, years):
                yf.SetMarkerColor(COLORS[cnt])
                yf.SetLineColor(COLORS[cnt])
                yf.SetMarkerStyle(20+cnt)
                yf.SetMarkerSize(1)
                if cnt==0:
                    yf.SetMaximum(1.2)
                    yf.SetMinimum(0)
                    yf.GetXaxis().SetTitle(MET_ET.title)
                    yf.GetYaxis().SetTitle("E^{mis}_{T} Trigger Efficiency")
                    yf.Draw("LP")
                else:
                    yf.Draw("LP SAME")
                legend.AddEntry(yf, yr, "LP")
                cnt += 1

            labels = label_plot(canvas, 
                category="", data_info="#int L dt =%0.2f fb^{-1}; #sqrt{13} TeV"%(total_lumi), textsize=18)    
            for lb in labels:
                lb.Draw("SAME")
            legend.Draw("SAME")
                    
            com_outname = "%s/MET_trig_eff%s_COMBINED"%(pdir, variation.name)
            log.info("Saving %s"%com_outname)
            for fmt in formats:
                canvas.Print(com_outname+fmt)

            canvas.Clear()
            legend.Clear()
    canvas.Close()
                    
##------------------------------------------------------------------------------------
## - - main driver
##------------------------------------------------------------------------------------
if __name__=="__main__":
    start_time = time.time()
    
    trigger_hists = get_trig_hists()
    fit_funcs, fit_params = fit_eff(trigger_hists)
    draw_fits(fit_funcs, fit_params, overlay_syst=True)
    
    end_time = time.time()
    elapsed_time = (end_time - start_time)/60.
    log.info("\n****************** elapsed time: %0.1f mins ******************"%elapsed_time)
