#!/usr/bin/env python
"""
* This scripts provieds functionalities for trainning a binary classifier in order to separate signal from background.
* It's build on top of the MVA with the option for Pythonic keras & scikit-learn backends.
"""

## stdlib
import os, sys, glob, multiprocessing
from subprocess import call
from os import environ

## - -  parse ana args (needed before ROOT)
from hpana.cmd import get_clf_parser 
clf_parser = get_clf_parser()
CLF_ARGS = clf_parser.parse_args()

## PyPI
from root_numpy import root2array, tree2array
import h5py
import numpy as np

## local
from hpana.config import Configuration
from hpana.analysis import Analysis
from hpana.samples.sample  import Sample
from hpana.variables import CLF_FEATURES
from hpana.classifier import Classifier, SClassifier, train_model
from hpana.categories import CLASSIFIER_CATEGORIES
from hpana.cluster.parallel import run_pool, Job
from hpana import log

## - - set log level
log.setLevel(CLF_ARGS.log)

# - - speed things up a bit
import ROOT
ROOT.SetSignalPolicy(ROOT.kSignalFast)
ROOT.gROOT.SetBatch(True)
log.info("ROOT is in batch mode")

##-------------------------------------------------------------
## consts 
##-------------------------------------------------------------
TREE_NAME = "NOMINAL"
N_TRACKS = [1]
FOLD_CUT_STR = "event_number%{0}!={1}"

MASS_RANGES = [
    (80, 90, 100, 110, 120), #< low mas 
    (130, 140, 150, 160), #< int mass I
    (170, 180, 190), #< int mass II
    (200, 225, 250, 300, 350, 400), #< high mass I
    range(500, 1100, 100) + range(1200, 2200, 200) + [2500, 3000], #< high mass II
] 

## - - build analysis main configuration object
CONFIG = Configuration(CLF_ARGS.channel, 
                       data_streams=CLF_ARGS.data_streams,
                       mc_campaign=CLF_ARGS.mc_campaign,
                       db_version=CLF_ARGS.db_version)

## - - instantiate Analysis
ANALYSIS  = Analysis(CONFIG, compile_cxx=True)

## - - training samples ["TTbar", "SingleTop", "Wtaunu", "Ztautau", "DiBoson"]
BKGS = filter(lambda s: s.name in ["TTbar", "SingleTop", "Wtaunu", "Ztautau", "DiBoson"], ANALYSIS.backgrounds)
SIGS = ANALYSIS.get_signals(masses=[m for mr in MASS_RANGES for m in mr])

## - - training features
FEATS = CLF_FEATURES[CLF_ARGS.channel]

## - - setup outdir
os.system("mkdir -p %s"%CLF_ARGS.outdir)
    
##-----------------------------
## sklearn backend 
##-----------------------------
if CLF_ARGS.backend=="sklearn":
    try:
        import sklearn
    except ImportError:
        raise RuntimeError("Please install sklearn; (pip install sklearn)")

    ## - - event number for kfold training and ntracks for different training for different tau prongs. 
    BRACHES = ["event_number"] + ["tau_0_n_charged_tracks"] + [ft.tformula for ft in FEATS]
    mparams = {
        "n_estimators":200, 
        "min_weight_fraction_leaf": 0.02,
        "max_depth": 10,
        "verbose":1,
        "learning_rate":0.1,
        }
    clf_type = "GB%i"%mparams["n_estimators"]

    ## - - prepare training Dataframe
    DFRAME = SClassifier.prepare_data(BKGS, SIGS, FEATS,
                                      channel=CLF_ARGS.channel, branches=BRACHES, train_data=CLF_ARGS.train_data)
    jobs = []
    for signal_masses in MASS_RANGES:
        mass_tag = "%ito%i"%(signal_masses[0], signal_masses[-1]) if signal_masses else "ALL_MASSES"
        signals = ANALYSIS.get_signals(masses=signal_masses)
        dframe = DFRAME.loc[[bkg.name for bkg in BKGS]+[sig.name for sig in signals]]
    
        for ntracks in N_TRACKS:
            for rem in range(CLF_ARGS.kfolds):
                sdf = dframe[(dframe["event_number"]%CLF_ARGS.kfolds!=rem) & (dframe["tau_0_n_charged_tracks"]==ntracks)]

                ## - - training arrays
                X_train = sdf[[ft.name for ft in CLF_FEATURES[CLF_ARGS.channel] ]] 
                Y_train = sdf["class_label"]
                X_weight = sdf["weight"] #<! pass it sample_weight to the fit method

                log.info("Training in mass rage:%s on ntracks=%i, nfold=%i, nevents=%i, and nfeatures=%i"%(
                    mass_tag, ntracks, rem, X_train.shape[0], X_train.shape[1]))

                ## - - instantiate the model
                clf_name = SClassifier.MODEL_NAME_STR_FORMAT.format(
                    clf_type, CLF_ARGS.channel, mass_tag, ntracks, CLF_ARGS.kfolds, rem, X_train.shape[1])
                sclf = SClassifier(CLF_ARGS.channel, name=clf_name, **mparams)

                ## correlation matrix ?
                if CLF_ARGS.plot_correlations:
                    from hpana.classifier import features_correlation
                    if rem !=1: #<! should be enough 
                        continue
                    p_title = r"Correlation Matrix: $ %i \leq m_{H^+} \leq %i [GeV]$"%(signal_masses[0], signal_masses[-1])
                    features_correlation(X_train, CLF_FEATURES[CLF_ARGS.channel], outname=clf_name.replace(".pkl", ""), outdir=CLF_ARGS.outdir, title=p_title)

                ## - - assign the job
                jobs.append(Job(train_model, sclf, X_train, Y_train, X_weight,
                                weight_sample=False, outdir=CLF_ARGS.outdir, validation_plots=CLF_ARGS.validation_plots))
    ## - - run
    if CLF_ARGS.parallel:
        run_pool(jobs, n_jobs=-1)
    else:
        run_pool(jobs, n_jobs=1)
        
        
##-----------------------------
## tmva backend
##-----------------------------
else:
    ## - - initialize TMVA
    ROOT.TMVA.Tools.Instance()
    ROOT.TMVA.PyMethodBase.PyInitialize()
    for signal_masses in MASS_RANGES:
        mass_tag = "%ito%i"%(signal_masses[0], signal_masses[-1]) if signal_masses else "ALL_MASSES"
        if CLF_ARGS.train_bdt:
            clf_name = "BDT_%s"%mass_tag
            clf_params = {
                "method_name": clf_name,
                "method_type": ROOT.TMVA.Types.kBDT,
                "output": "%s.root"%clf_name,
                "features": CLF_FEATURES[CLF_ARGS.channel],
                "outdir": CLF_ARGS.outdir,
            }
            tr_params = {
                "signal_masses": signal_masses,
                "method_params": "!H:!V:NTrees=100:MaxDepth=10:BoostType=AdaBoost:nCuts=20",
            }

            if CLF_ARGS.kfolds > 1:
                for rem in range(CLF_ARGS.kfolds):
                    fold_cut = ROOT.TCut(FOLD_CUT_STR.format(CLF_ARGS.kfolds, rem))
                    clf_params["method_name"] = "%s_mod_%i_rem_%i"%(clf_name, CLF_ARGS.kfolds, rem)
                    clf_params["output"] = "%s_mod_%i_rem_%i.root"%(clf_name, CLF_ARGS.kfolds, rem)

                    ## - - instantite classifier
                    bdt_classifier = Classifier(**clf_params)
                    bdt_classifier.train(backgrounds, signals, **tr_params)
            else:
                ## - - instantite classifier
                bdt_classifier = Classifier(**clf_params)
                bdt_classifier.train(backgrounds, signals, **tr_params)


        ##-----------------------------
        ## train Neural Networks
        ##-----------------------------
        if CLF_ARGS.train_nn:
            # Select Theano as backend for Keras
            environ['KERAS_BACKEND'] = 'theano'

            # Set architecture of system (AVX instruction set is not supported on SWAN)
            environ['THEANO_FLAGS'] = 'gcc.cxxflags=-march=corei7'
            from keras.models import Sequential
            from keras.layers import Dense

            clf_name = "NN_%s"%mass_tag
            clf_params = {
                "method_name": clf_name,
                "method_type": ROOT.TMVA.Types.kPyKeras,
                "output": "%s.root"%clf_name,
                "features": CLF_FEATURES[CLF_ARGS.channel],
                "outdir": CLF_ARGS.outdir,
            }
            tr_params = {
                "signal_masses": signal_masses,
            }

            if CLF_ARGS.kfolds > 1:
                for rem in range(CLF_ARGS.kfolds):
                    model = Sequential()
                    model.add(Dense(64, activation='relu', input_dim=len(input_features)))
                    model.add(Dense(2, activation='softmax'))
                    model.summary()
                    model.compile(loss='categorical_crossentropy',
                              optimizer="adam", metrics=['accuracy', ])
                    model_name = "%s/%s_model_mod_%i_rem_%i.h5"%(CLF_ARGS.outdir, clf_name, CLF_ARGS.kfolds, rem)
                    model.save(model_name)
                    method_params = "H:!V:VarTransform=N:FilenameModel=%s:NumEpochs=10:BatchSize=32"%model_name

                    fold_cut = ROOT.TCut(FOLD_CUT_STR.format(CLF_ARGS.kfolds, rem))
                    clf_params["method_name"] = "%s_mod_%i_rem_%i"%(clf_name, CLF_ARGS.kfolds, rem)
                    clf_params["output"] = "%s_mod_%i_rem_%i.root"%(clf_name, CLF_ARGS.kfolds, rem)

                    ## - - instantite classifier
                    nn_classifier = Classifier(**clf_params)
                    nn_classifier.train(backgrounds, signals, method_params=method_params, **tr_params)
            else:
                model = Sequential()
                model.add(Dense(64, activation='relu', input_dim=len(input_features)))
                model.add(Dense(2, activation='softmax'))
                model.summary()
                model.compile(loss='categorical_crossentropy',
                              optimizer="adam", metrics=['accuracy', ])
                model_name = "%s/%s_model.h5"%(CLF_ARGS.outdir, clf_name)
                model.save(model_name)
                method_params = "H:!V:VarTransform=N:FilenameModel=%s:NumEpochs=10:BatchSize=32"%model_name

                ## - - instantite classifier
                nn_classifier = Classifier(**clf_params)
                nn_classifier.train(backgrounds, signals, method_params=method_params, **tr_params)

