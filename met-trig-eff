#! /usr/bin/env python

"""
* This script provides functionalities for evaluating MET trigger efficiency. 
* The Emiss trigger is not well described in simulation. The strategy for the treatment of the Emiss trigger in
* simulation is to derive the trigger efficiency from data in bins of offline Emiss. The binned Emiss-dependent
* efficiency is transformed into a continuous efficiency by fitting it to the error function. This is done to
* remove bias caused by the binning. Simulated events are weighted using the efficiency curve, based on
* the offline Emiss in the event.
* EFF =  (event selections + given trigger)/(event selections)
"""

## stdlib
import os, sys, time, array, pickle, yaml 
import multiprocessing

## local
from hpana.config import Configuration
from hpana.analysis import Analysis
from hpana.categories import MET_TRIG_EFF_CRs
from hpana.variables import met_et as MET_ET
from hpana.trigger import MET_TRIGGERS
from hpana.dataset_hists import dataset_hists
from hpana.cluster.parallel import close_pool
from hpana import log

## parse args (needed before ROOT)
from hpana.cmd import get_trig_eff_parser
eff_parser = get_trig_eff_parser()
TRIG_EFF_ARGS = eff_parser.parse_args()


## set log level
log.setLevel(TRIG_EFF_ARGS.log)

## Speed things up a bit
import ROOT
ROOT.SetSignalPolicy(ROOT.kSignalFast)
ROOT.gROOT.SetBatch(True)
log.info("ROOT is in batch mode")
ROOT.gErrorIgnoreLevel = ROOT.kWarning #<! turn off useless ROOT Info messages
ROOT.Math.MinimizerOptions.SetDefaultMinimizer("Minuit2")


##------------------------------------------------------------------------------------
## - - consts
##------------------------------------------------------------------------------------
ERR_FUNC_STR = "{0}*(1 + TMath::Erf((met_et - {1})/{2}))+{3}"
MET_ET.bins = range(0, 200, 20) + range(200, 400, 50)
COLORS = [ROOT.kRed, ROOT.kBlue, ROOT.kGreen, ROOT.kMagenta, ROOT.kOrange, ROOT.kYellow]

##------------------------------------------------------------------------------------
## - - build the taulep analysis (run only on relevant streams) 
##------------------------------------------------------------------------------------
def get_trig_hists(triggers=MET_TRIGGERS,
                   categories=MET_TRIG_EFF_CRs,
                   db_version=TRIG_EFF_ARGS.db_version,
                   data_streams=TRIG_EFF_ARGS.data_streams,
                   hists_cache=TRIG_EFF_ARGS.hists_cache,
                   parallel=TRIG_EFF_ARGS.parallel,
                   dry_run=TRIG_EFF_ARGS.dry_run,
                   ncpu=TRIG_EFF_ARGS.ncpu):
    """
    Given a dictionary of triggers, produce histograms with and without trigger and save their ratio.
    """
    update_cache = True
    ratio_hists = {}
    hists = []
    if hists_cache and os.path.isfile(hists_cache):
        log.info("loading hists from %s"%hists_cache)
        update_cache = False
        with open(hists_cache, "r") as cfile:
            ratio_hists = pickle.load(cfile)
            if (not isinstance(ratio_hists, dict) or not ratio_hists):
                update_cache = True
                log.info("can't load hists from %s!; calculating them on the fly"%hists_cache)
            else:    
                for i, ds in enumerate(data_streams):
                    if not ds in ratio_hists:
                        update_cache = True
                        
    if update_cache:
        workers = []
        for year, trig_dict in triggers.iteritems():
            if not year in data_streams:
                continue
            config = Configuration("taulep", data_streams=(year,), mc_campaign="mc16", db_version=db_version)
            analysis = Analysis(config, compile_cxx=True)
            samples = [analysis.data]

            """
            ## since we want to vary the tauid (already included in MET_TRIG_EFF_CRs),
            ## we pass global tauid=ROOT.TCut("1>0").
            """
            for trigger, info in trig_dict.iteritems():
                workers_with_trigger = analysis.workers(
                    channel="taulep", fields=[MET_ET], categories=categories, samples=samples,
                    trigger=info["TRIGGER"], tauid=ROOT.TCut(""))
                for wt in workers_with_trigger:
                    wt.name = "%s.%s.%s"%(wt.name, year, trigger)
                    workers.append(wt)
                    
                workers_without_trigger = analysis.workers(
                    channel="taulep", fields=[MET_ET], categories=categories, samples=samples,
                    trigger=info["NO_TRIGGER"], tauid=ROOT.TCut(""))
                for wto in workers_without_trigger:
                    wto.name = "%s.%s.%s.NO_TRIGGER"%(wto.name, year, trigger)
                    workers.append(wto)
                    
        if dry_run:
            log.info(workers)
            return 
        if parallel:
            log.info(
                "************** submitting %i jobs  ************"%len(workers))
            log.info(
                "***********************************************")

            pool = multiprocessing.Pool(ncpu)
            results = [pool.apply_async(dataset_hists, (wk,)) for wk in workers]
            # - - close the pool
            close_pool(pool)
            for res in results:
                hists += res.get(36000) #<! without the timeout this blocking call ignores all signals.
        else:
            for w in workers:
                hists += [dataset_hists(w)]

        ## - - now get the selection+trig/selection histogram
        for year, trig_dict in triggers.iteritems():
            if not year in data_streams:
                continue
            yhists = filter(lambda hs: year in hs.name, hists)
            ratio_hists[year] = {}
            for trigger in trig_dict.keys():
                ratio_hists[year][trigger] = {}
                for category in categories:
                    hs_cat = filter(lambda hs: hs.category==category.name, yhists)
                    hset_trig = filter(lambda hs: hs.name.endswith(trigger), hs_cat)
                    hset_no_trig = filter(lambda hs: hs.name.endswith("%s.NO_TRIGGER"%trigger), hs_cat)

                    hist_trig = reduce(lambda h1, h2: h1+h2, [hs.hist for hs in hset_trig])
                    hist_no_trig = reduce(lambda h1, h2: h1+h2, [hs.hist for hs in hset_no_trig])
                    
                    log.info("***** year: %s; category: %s; trigger: %s *****"%(year, category.name, trigger))
                    log.info("***** category+trigger: %i; category: %i *****"%(
                        hist_trig.Integral(0, -1), hist_no_trig.Integral(0, -1)))
                    
                    assert (hist_trig and hist_no_trig), "couldn't retrieve hists for %s"%category.name

                    ## The error per bin will be computed as sqrt(sum of squares of weight) for each bin.
                    hist_trig.Sumw2()
                    hist_no_trig.Sumw2()
                    hist_trig.Divide(hist_no_trig)
                    ratio_hists[year][trigger][category.name] = hist_trig
                    
        ## cache them
        log.info("updating met trig eff hists cache")
        if os.path.isfile(hists_cache):
            os.system("rm %s"%hists_cache)
        if not hists_cache:
            hist_cache = "met_trig_HISTS.pkl"
        with open(hists_cache, "w") as hfile:
            pickle.dump(ratio_hists, hfile)
            
    return ratio_hists

##------------------------------------------------------------------------------------
## - - fit error function to the histograms
##------------------------------------------------------------------------------------
def fit_eff(eff_hists,
            eff_cache="metTrigEff.cxx",
            num_params=4):
    """

    """

    ## - - first let's get the total lumi 
    total_lumi = 0
    for y, trgs in eff_hists.iteritems():
        for trg in trgs:
            total_lumi += MET_TRIGGERS[y][trg]["LUMI"]
            
    ## - - do the fit per trigger per variation
    fit_params  = {}
    fit_funcs = {}
    for year, triggers in eff_hists.iteritems():
        fit_funcs[year] = {}
        for trigger, variations in triggers.iteritems():
            lumi = MET_TRIGGERS[year][trigger]["LUMI"]
            fit_funcs[year][trigger] = {}
            for variation, hist in variations.iteritems():
                if not variation in fit_params:
                    fit_params[variation] = []
                log.info("performing error function fit for %s trigger & %s region"%(trigger, variation))

                ## - - initialize the function with some reasonable parameters 
                err_function = ROOT.TF1("erf", "[0]*(1 + TMath::Erf((x-[1])/[2]))+[3]", 0, 500)
                err_function.SetParameters(0.5, 100, 50, 0)
                
                ## - - fit and retrieve the function 
                hist.Fit(err_function, "EM")
                fit_func = hist.GetFunction("erf")
                params = [fit_func.GetParameter(n) for n in range(num_params)]
                fit_params[variation] += ["%0.4f * (%s)"%(lumi/total_lumi, ERR_FUNC_STR.format(*params))]
                fit_funcs[year][trigger][variation] = (hist, fit_func)

    if eff_cache:
        with open(eff_cache, "w") as cfile:
            istring = "float metTrigEff(float met_et, int variation_index){\n"
            cfile.write(istring)
            index = 1000
            for n, variation in enumerate(MET_TRIG_EFF_CRs):
                cfile.write("\t //! variation: %s\n"%variation.name)
                cfile.write("\t if(variation_index==%i){\n"%(index+n))
                cfile.write("\t\t return %s;"%(" + ".join(fit_params[variation.name]) ) )
                cfile.write("\t}\n\n")
            cfile.write("\telse \n return 1.; \n}")
            
    return fit_funcs, fit_params

##------------------------------------------------------------------------------------
## - - plot fit functions 
##------------------------------------------------------------------------------------
def draw_fits(fit_funcs, pdir=TRIG_EFF_ARGS.pdir, overlay=True):
    """ Given a dict of hists, fit funcs draw them 
    """
    canvas = ROOT.TCanvas()
    for year, fits in fit_funcs.iteritems():
        triggers = fits.keys()
        variations = filter(lambda var: var.name in fit_funcs[year][triggers[0]].keys(), MET_TRIG_EFF_CRs)
        for trigger in triggers:
            lumi = MET_TRIGGERS[year][trigger]["LUMI"]
            if overlay:
                legend = ROOT.TLegend(0.15, 0.7, 0.45, 0.85)
            else:
                legend = ROOT.TLegend(0.15, 0.8, 0.45, 0.85)
                
            rlabel = ROOT.TLatex(
                canvas.GetLeftMargin() + 0.45,
                1 - canvas.GetTopMargin() - 0.055,
                '#bf{%s} (%s, %0.2f fb^{-1})'%(trigger, year, lumi))
            rlabel.SetNDC()
            rlabel.SetTextFont(43)
            rlabel.SetTextSize(15)
            rlabel.SetTextAlign(31)
            
            for n, variation in enumerate(variations):
                hist, fit_func = fits[trigger][variation.name]
                if overlay:
                    fit_func.SetLineColor(COLORS[n])
                else:
                    fit_func.SetLineColor(COLORS[0])
                    
                if n==0:
                    hist.GetXaxis().SetTitle(MET_ET.title)
                    hist.GetYaxis().SetTitle("efficiency")
                    hist.Draw("PE1")
                    fit_func.Draw("P SAME")
                if overlay:    
                    fit_func.Draw("EP SAME")
                    legend.AddEntry(fit_func, variation.label, "L")
                else:
                    hist.GetXaxis().SetTitle(MET_ET.title)
                    hist.GetYaxis().SetTitle("efficiency")
                    hist.Draw("PE1")
                    fit_func.Draw("P SAME")
                    legend.AddEntry(fit_func, variation.label, "L")

                    legend.Draw("SAME")
                    rlabel.Draw("SAME")
                    os.system("mkdir -p %s"%pdir)
                    canvas.Print("%s/MET_trig_eff%s_%s_%s.png"%(pdir, year, variation.name, trigger))
                    legend.Clear()
                    canvas.Clear()
            if overlay:
                legend.Draw("SAME")
                rlabel.Draw("SAME")
                os.system("mkdir -p %s"%pdir)
                canvas.Print("%s/MET_trig_eff%s_%s.png"%(pdir, year, trigger))
                legend.Clear()
                canvas.Clear()
            
    canvas.Close()
                    
##------------------------------------------------------------------------------------
## - - main driver
##------------------------------------------------------------------------------------
if __name__=="__main__":
    start_time = time.time()
    
    trigger_hists = get_trig_hists()
    fit_funcs, fit_params = fit_eff(trigger_hists)
    draw_fits(fit_funcs, overlay=True)
    
    end_time = time.time()
    elapsed_time = (end_time - start_time)/60.
    log.info("\n****************** elapsed time: %0.1f mins ******************"%elapsed_time)
